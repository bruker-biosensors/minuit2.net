using minuit2.net;
using minuit2.net.CostFunctions;
using minuit2.net.Minimizers;
using minuit2.UnitTests.TestUtilities;
using static minuit2.net.MinimizationExitCondition;

namespace minuit2.UnitTests;

[TestFixture]
public class The_migrad_minimizer() : Any_parameter_uncertainty_resolving_minimizer(MigradMinimizer)
{
    private static readonly IMinimizer MigradMinimizer = Minimizer.Migrad;

    [Description("Expected values are generated by iminuit, the Minuit2 wrapper for Python, for the same scenarios.")]
    public class When_minimizing_a_least_squares_cost_function
    {
        [TestCase(false, 100), 
         TestCase(true, 78)]
        public void yields_the_expected_result(bool hasGradient, int expectedFunctionCalls)
        {
            var cost = CubicPolynomial.LeastSquaresCost.WithGradient(hasGradient).Build();
            var parameterConfigurations = CubicPolynomial.ParameterConfigurations.Defaults;
            
            var result = MigradMinimizer.Minimize(cost, parameterConfigurations);

            result.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(4).And
                .HaveNumberOfFunctionCallsCloseTo(expectedFunctionCalls).And
                .HaveCostValue(12.49).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 0.005623, -0.004301, 0.000881, -5.271e-05 },
                    { -0.004301, 0.004923, -0.001177, 7.655e-05 },
                    { 0.000881, -0.001177, 0.0003037, -2.067e-05 },
                    { -5.271e-05, 7.655e-05, -2.067e-05, 1.45e-06 }
                });
        }
        
        [TestCase(false, 31), 
         TestCase(true, 31)]
        public void with_fixed_parameters_yields_the_expected_result(bool hasGradient, int expectedFunctionCalls)
        {
            var cost = CubicPolynomial.LeastSquaresCost.WithGradient(hasGradient).Build();
            var parameterConfigurations = new[]
            {
                CubicPolynomial.ParameterConfigurations.C0,
                CubicPolynomial.ParameterConfigurations.C1.Fixed(),
                CubicPolynomial.ParameterConfigurations.C2,
                CubicPolynomial.ParameterConfigurations.C3.Fixed()
            };

            var result = MigradMinimizer.Minimize(cost, parameterConfigurations);

            result.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(2).And
                .HaveNumberOfFunctionCallsCloseTo(expectedFunctionCalls).And
                .HaveCostValue(437.7).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([9.411, -1.97, 1.088, -0.11]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 0.001092, 0.0, -1.918e-05, 0.0 },
                    { 0.0, 0.0, 0.0, 0.0 },
                    { -1.918e-05, 0.0, 6.211e-07, 0.0 },
                    { 0.0, 0.0, 0.0, 0.0 }
                });
        }
        
        [Test]
        public void with_limited_parameters_yields_the_expected_result()
        {
            var cost = CubicPolynomial.LeastSquaresCost.Build();
            var parameterConfigurations = new[]
            {
                CubicPolynomial.ParameterConfigurations.C0.WithLimits(CubicPolynomial.ParameterConfigurations.C0.Value - 0.25, null),
                CubicPolynomial.ParameterConfigurations.C1,
                CubicPolynomial.ParameterConfigurations.C2,
                CubicPolynomial.ParameterConfigurations.C3.WithLimits(null, CubicPolynomial.ParameterConfigurations.C3.Value + 0.005)
            };

            var result = MigradMinimizer.Minimize(cost, parameterConfigurations);

            result.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(4).And
                .HaveNumberOfFunctionCallsCloseTo(444).And
                .HaveCostValue(62.34).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([10.5, -2.39, 1.082, -0.105]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 7.023e-09, -3.654e-09, 3.124e-10, -1.261e-14 },
                    { -3.654e-09, 0.0002602, -3.344e-05, 5.468e-09 },
                    { 3.124e-10, -3.344e-05, 4.594e-06, -1.873e-09 },
                    { -1.261e-14, 5.468e-09, -1.873e-09, 1.211e-10 }
                }, relativeTolerance: 0.003);
        }
        
        [Test]
        public void with_an_analytical_gradient_and_with_limited_parameters_yields_the_expected_result()
        {
            var cost = CubicPolynomial.LeastSquaresCost.WithGradient().Build();
            var parameterConfigurations = new[]
            {
                CubicPolynomial.ParameterConfigurations.C0.WithLimits(CubicPolynomial.ParameterConfigurations.C0.Value - 0.25, null),
                CubicPolynomial.ParameterConfigurations.C1,
                CubicPolynomial.ParameterConfigurations.C2,
                CubicPolynomial.ParameterConfigurations.C3.WithLimits(null, CubicPolynomial.ParameterConfigurations.C3.Value + 0.005)
            };

            var result = MigradMinimizer.Minimize(cost, parameterConfigurations);

            // Covariances are slightly different from the numerical-gradient case (above).
            // This is because, in contrast to proper convergence, in case of early termination at parameter limits the
            // assumption of local quadratic behavior (parabolic approximation) around the terminal cost value is
            // generally not fulfilled. Therefore, covariances are not fully robust.
            result.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(4).And
                .HaveNumberOfFunctionCallsCloseTo(156).And
                .HaveCostValue(62.34).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([10.5, -2.39, 1.082, -0.105]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 5.482e-09, -2.933e-09, 2.507e-10, -7.976e-15 },
                    { -2.933e-09, 0.0002602, -3.343e-05, 4.309e-09 },
                    { 2.507e-10, -3.343e-05, 4.589e-06, -1.476e-09 },
                    { -7.976e-15, 4.309e-09, -1.476e-09, 9.18e-11 }
                });
        }
        
        [Test]
        public void with_unknown_data_errors_yields_the_expected_result([Values] bool hasGradient)
        {
            var cost = CubicPolynomial.LeastSquaresCost.WithMissingYErrors().WithGradient(hasGradient).Build();

            var result = MigradMinimizer.Minimize(cost, CubicPolynomial.ParameterConfigurations.Defaults);

            result.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(4).And
                .HaveCostValue(0.1249).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 0.5623, -0.4301, 0.08809, -0.00527 },
                    { -0.4301, 0.4922, -0.1177, 0.007654 },
                    { 0.08809, -0.1177, 0.03036, -0.002067 },
                    { -0.00527, 0.007654, -0.002067, 0.000145 }
                });
        }
        
        [Test]
        public void with_unknown_data_errors_and_subsequently_applying_error_refinement_yields_the_expected_result(
            [Values] bool hasGradient)
        {
            var cost = CubicPolynomial.LeastSquaresCost.WithMissingYErrors().WithGradient(hasGradient).Build();
            var parameterConfigurations = CubicPolynomial.ParameterConfigurations.Defaults;
            
            var result = MigradMinimizer.Minimize(cost, parameterConfigurations);
            var adjustedCost = cost.WithErrorDefinitionAdjustedWhereRequiredBasedOn(result);
            var adjustedResult = HesseErrorCalculator.Refine(result, adjustedCost);

            adjustedResult.Should()
                .HaveExitCondition(Converged).And
                .HaveIsValid(true).And
                .HaveNumberOfVariables(4).And
                .HaveCostValue(0.1249).And
                .HaveParameters(["c0", "c1", "c2", "c3"]).And
                .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
                .HaveParameterCovarianceMatrix(new[,]
                {
                    { 0.004391, -0.003358, 0.0006878, -4.115e-05 },
                    { -0.003358, 0.003843, -0.0009193, 5.977e-05 },
                    { 0.0006878, -0.0009193, 0.0002371, -1.614e-05 },
                    { -4.115e-05, 5.977e-05, -1.614e-05, 1.132e-06 }
                });
        }
    }
}