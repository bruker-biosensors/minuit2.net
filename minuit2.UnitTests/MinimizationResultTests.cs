using FluentAssertions;
using FluentAssertions.Execution;
using minuit2.net;

namespace minuit2.UnitTests;

[Description("""
             Minimization results for various scenarios are validated through comparison with the output generated by 
             iminuit, the Minuit2 wrapper for Python.
             """)]
public class MinimizationResultTests
{
    private static readonly Func<double, IList<double>, double> CubicPoly = 
        (x, c) => c[0] + c[1] * x + c[2] * x * x + c[3] * x * x * x;
    
    private static readonly Func<double, IList<double>, IList<double>> CubicPolyGrad = 
        (x, _) => [1, x, x * x, x * x * x];
    
    private static readonly List<double> XValues = 
    [
        0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5, 4, 4.5, 5, 5.5, 6, 6.5, 7, 7.5, 8, 8.5, 9, 9.5
    ];

    // y-values are generated using a cubic polynomial with coefficients: c0 = 10, c1 = -2, c2 = 1, c3 = -0.1
    // and a random normal noise with a standard deviation of 0.1
    private static readonly List<double> YValues =
    [
        9.9, 9.2, 9.03, 8.93, 9.29, 9.75, 10.24, 11.02, 11.57, 12.11, 12.51, 12.46, 12.52, 11.72, 10.8, 9.08, 6.95,
        3.77, 0.07, -4.45
    ];

    private const double YError = 0.1;  // standard deviation of noise used to generate the above y-values

    
    private static IEnumerable<Func<double, IList<double>, IList<double>>?> GradientTestCases()
    {
        yield return null;
        yield return CubicPolyGrad;
    }
    
    [TestCaseSource(nameof(GradientTestCases))]
    public void basic_scenario(Func<double, IList<double>, IList<double>>? analyticalGradient)
    {
        var cost = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient);
        
        ParameterConfiguration[] parameterConfigurations = 
        [
            new("c3", -0.11), 
            new("c2", 1.13), 
            new("c0", 10.75), 
            new("c1", -1.97)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(4).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(12.49).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 0.005623, -0.004301, 0.000881, -5.271e-05 },
                { -0.004301, 0.004923, -0.001177, 7.655e-05 },
                { 0.000881, -0.001177, 0.0003037, -2.067e-05 },
                { -5.271e-05, 7.655e-05, -2.067e-05, 1.45e-06 }
            });
    }

    [TestCase(double.NegativeInfinity, double.PositiveInfinity)]
    [TestCase(double.NaN, double.PositiveInfinity)]
    [TestCase(double.NegativeInfinity, double.NaN)]
    [TestCase(double.NaN, double.NaN)]
    [Description("Ensure that the minimizer handles infinite bounds the same way as if there were no bounds")]
    public void basic_scenario_with_explicitly_provided_infinite_bounds(double lowerLimit, double upperLimit)
    {
        var cost = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly);

        ParameterConfiguration[] parameterConfigurations =
        [
            new("c3", -0.11, LowerLimit: lowerLimit, UpperLimit: upperLimit),
            new("c2", 1.13, LowerLimit: lowerLimit, UpperLimit: upperLimit),
            new("c0", 10.75, LowerLimit: lowerLimit, UpperLimit: upperLimit),
            new("c1", -1.97, LowerLimit: lowerLimit, UpperLimit: upperLimit)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should().HaveIsValid(true).And.HaveCostValue(12.49);
    }
    
    [TestCaseSource(nameof(GradientTestCases))]
    public void fixed_parameters_scenario(Func<double, IList<double>, IList<double>>? analyticalGradient)
    {
        var cost = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient);

        ParameterConfiguration[] parameterConfigurations =
        [
            new("c3", -0.11, IsFixed: true),
            new("c2", 1.13),
            new("c1", -1.97, IsFixed: true),
            new("c0", 10.75)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(2).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(437.7).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([9.411, -1.97, 1.088, -0.11]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 0.001092, 0.0, -1.918e-05, 0.0 },
                { 0.0, 0.0, 0.0, 0.0 },
                { -1.918e-05, 0.0, 6.211e-07, 0.0 },
                { 0.0, 0.0, 0.0, 0.0 }
            });
    }

    [Test]
    public void limited_parameters_scenario()
    {
        var cost = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly);

        ParameterConfiguration[] parameterConfigurations =
        [
            new("c3", -0.11, UpperLimit: -0.105),
            new("c2", 1.13),
            new("c1", -1.97),
            new("c0", 10.75, LowerLimit: 10.5)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(4).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(62.34).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([10.5, -2.39, 1.082, -0.105]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 7.023e-09, -3.654e-09, 3.124e-10, -1.261e-14 },
                { -3.654e-09, 0.0002602, -3.344e-05, 5.468e-09 },
                { 3.124e-10, -3.344e-05, 4.594e-06, -1.873e-09 },
                { -1.261e-14, 5.468e-09, -1.873e-09, 1.211e-10 }
            }, relativeTolerance: 0.003);  
    }
    
    [Test]
    public void limited_parameters_scenario_with_analytical_gradient()
    {
        var cost = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, CubicPolyGrad);

        ParameterConfiguration[] parameterConfigurations =
        [
            new("c3", -0.11, UpperLimit: -0.105),
            new("c2", 1.13),
            new("c1", -1.97),
            new("c0", 10.75, LowerLimit: 10.5)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(4).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(62.34).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([10.5, -2.39, 1.082, -0.105]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 5.482e-09, -2.933e-09, 2.507e-10, -7.976e-15 },
                { -2.933e-09, 0.0002602, -3.343e-05, 4.309e-09 },
                { 2.507e-10, -3.343e-05, 4.589e-06, -1.476e-09 },
                { -7.976e-15, 4.309e-09, -1.476e-09, 9.18e-11 }
            });
    }
    
    private static IEnumerable<object> MixedGradientTestCases()
    {
        yield return new object?[] { null, false };
        yield return new object[] { CubicPolyGrad, true };
        yield return new object[] { CubicPolyGrad, false };
    }

    [TestCaseSource(nameof(MixedGradientTestCases))]
    public void global_parameters_scenario(Func<double, IList<double>, IList<double>>? analyticalGradient, bool areAllGradientsDefined)
    {
        var cost = new CostFunctionSum(
            new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient),
            new LeastSquares(XValues, YValues, YError, ["c0", "c1_1", "c2", "c3_1"], CubicPoly, analyticalGradient),
            new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2_2", "c3"], CubicPoly, areAllGradientsDefined ? analyticalGradient : null));
        
        ParameterConfiguration[] parameterConfigurations =
        [
            new("c2_2", 0.9),
            new("c3_1", -0.15),
            new("c1_1", -2.1),
            new("c3", -0.11),
            new("c2", 1.13),
            new("c1", -1.97),
            new("c0", 10.75)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(7).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(37.48).And
            .HaveParameters(["c0", "c1", "c2", "c3", "c1_1", "c3_1", "c2_2"]).And
            .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931, -1.959, -0.09931, 0.9898]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 0.001874, -0.001434, 0.0002936, -1.757e-05, -0.001434, -1.757e-05, 0.0002936 },
                { -0.001434, 0.001658, -0.0003923, 2.527e-05, 0.001606, 2.601e-05, -0.0003926 },
                { 0.0002936, -0.0003923, 0.0001013, -6.886e-06, -0.0003926, -6.894e-06, 0.0001011 },
                { -1.757e-05, 2.527e-05, -6.886e-06, 4.879e-07, 2.601e-05, 4.745e-07, -6.894e-06 },
                { -0.001434, 0.001606, -0.0003926, 2.601e-05, 0.001709, 2.453e-05, -0.000392 },
                { -1.757e-05, 2.601e-05, -6.894e-06, 4.745e-07, 2.453e-05, 5.014e-07, -6.879e-06 },
                { 0.0002936, -0.0003926, 0.0001011, -6.894e-06, -0.000392, -6.879e-06, 0.0001015 }
            });
    }

    [TestCaseSource(nameof(GradientTestCases))]
    public void missing_data_uncertainties_scenario(Func<double, IList<double>, IList<double>>? analyticalGradient)
    {
        var cost = new LeastSquares(XValues, YValues, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient);

        ParameterConfiguration[] parameterConfigurations =
        [
            new("c3", -0.11),
            new("c2", 1.13),
            new("c0", 10.75),
            new("c1", -1.97)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(4).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(0.1249).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 0.004391, -0.003358, 0.0006878, -4.115e-05 },
                { -0.003358, 0.003843, -0.0009193, 5.977e-05 },
                { 0.0006878, -0.0009193, 0.0002371, -1.614e-05 },
                { -4.115e-05, 5.977e-05, -1.614e-05, 1.132e-06 }
            });
    }

    [TestCaseSource(nameof(GradientTestCases)), 
     Description("""
                 When minimizing a sum of least squares, the parameter covariances should be auto-scaled when any 
                 of the cost functions have missing data uncertainties. Our how would we do it otherwise?
                 """)]
    public void global_parameter_scenario_with_partly_missing_data_uncertainties(Func<double, IList<double>, IList<double>>? analyticalGradient)
    {
        var cost = new CostFunctionSum(
            new LeastSquares(XValues, YValues, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient), 
            new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient));

        ParameterConfiguration[] parameterConfigurations = 
        [
            new("c3", -0.11),
            new("c2", 1.13),
            new("c1", -1.97),
            new("c0", 10.75)
        ];
        
        var minimizer = new Migrad(cost, parameterConfigurations);
        var result = minimizer.Run();

        result.Should()
            .HaveIsValid(true).And
            .HaveNumberOfVariables(4).And
            .HaveNumberOfFunctionCallsGreaterThan(10).And
            .HaveReachedFunctionCallLimit(false).And
            .HaveConverged(true).And
            .HaveCostValue(12.62).And
            .HaveParameters(["c0", "c1", "c2", "c3"]).And
            .HaveParameterValues([9.974, -1.959, 0.9898, -0.09931]).And
            .HaveParameterCovarianceMatrix(new[,]
            {
                { 0.001951, -0.001493, 0.0003057, -1.829e-05 },
                { -0.001493, 0.001708, -0.0004086, 2.656e-05 },
                { 0.0003057, -0.0004086, 0.0001054, -7.172e-06 },
                { -1.829e-05, 2.656e-05, -7.172e-06, 5.033e-07 }
            });
    }
    
    private static IEnumerable<object> CostFunctionSumWithIndependentComponentsTestCases()
    {
        yield return new object?[] { null, MinimizationStrategy.Fast };
        yield return new object?[] { null, MinimizationStrategy.Balanced };
        yield return new object?[] { null, MinimizationStrategy.Precise };
        yield return new object[] { CubicPolyGrad, MinimizationStrategy.Fast };
        yield return new object[] { CubicPolyGrad, MinimizationStrategy.Balanced };
        yield return new object[] { CubicPolyGrad, MinimizationStrategy.Precise };
    }
    
    [TestCaseSource(nameof(CostFunctionSumWithIndependentComponentsTestCases))]
    public void A_cost_function_sum_with_a_single_component_when_minimized_should_yield_a_result_equivalent_to_the_result_of_the_isolated_component(
        Func<double, IList<double>, IList<double>>? analyticalGradient, MinimizationStrategy minimizationStrategy)
    {
        var component = new LeastSquares(XValues, YValues, YError, ["c0", "c1", "c2", "c3"], CubicPoly, analyticalGradient).WithUp(4);
        var sum = new CostFunctionSum(component);
        
        ParameterConfiguration[] parameterConfigurations = 
        [
            new("c0", 10.75), 
            new("c1", -1.97),
            new("c2", 1.13), 
            new("c3", -0.11)
        ];

        var componentResult = new Migrad(component, parameterConfigurations, minimizationStrategy).Run();
        var sumResult = new Migrad(sum, parameterConfigurations, minimizationStrategy).Run();
        
        componentResult.Should().BeEquivalentTo(sumResult, options => options
            .Excluding(x => x.NumberOfFunctionCalls)
            .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, Math.Abs(ctx.Expectation * 0.001)))
            .WhenTypeIs<double>());
    }

    [TestCaseSource(nameof(CostFunctionSumWithIndependentComponentsTestCases))]
    public void A_cost_function_sum_having_components_with_different_error_scales_not_sharing_any_parameters_when_minimized_should_yield_a_result_equivalent_to_the_results_of_the_isolated_components(
        Func<double, IList<double>, IList<double>>? analyticalGradient, MinimizationStrategy minimizationStrategy)
    {
        if (minimizationStrategy == MinimizationStrategy.Fast)
            Assert.Ignore("The fast minimization strategy currently leads to inconsistent covariances. " +
                          "In iminuit, this oddity is resolved by calling the Hesse algorithm after minimization. " +
                          "Once the additional Hesse call is added here, the tests should be re-enabled.");
        
        var component1 = new LeastSquares(XValues, YValues, YError, ["c0_1", "c1_1", "c2_1", "c3_1"], CubicPoly, analyticalGradient);
        var component2 = new LeastSquares(XValues, YValues, YError, ["c0_2", "c1_2", "c2_2", "c3_2"], CubicPoly, analyticalGradient).WithUp(4);
        var sum = new CostFunctionSum(component1, component2);

        ParameterConfiguration[] parameterConfigurations1 =
        [
            new("c0_1", 10.75),
            new("c1_1", -1.97),
            new("c2_1", 1.13),
            new("c3_1", -0.11)
        ];
        ParameterConfiguration[] parameterConfigurations2 =
        [
            new("c0_2", 10.75),
            new("c1_2", -1.97),
            new("c2_2", 1.13),
            new("c3_2", -0.11)
        ];

        var component1Result = new Migrad(component1, parameterConfigurations1, minimizationStrategy).Run();
        var component2Result = new Migrad(component2, parameterConfigurations2, minimizationStrategy).Run();
        var sumResult = new Migrad(sum, parameterConfigurations1.Concat(parameterConfigurations2).ToArray(), minimizationStrategy).Run();

        using (new AssertionScope())
        {
            sumResult.CostValue.Should().BeApproximately(component1Result.CostValue + component2Result.CostValue, sumResult.CostValue * 0.001);
            sumResult.ParameterValues.Take(4).Should().BeEquivalentTo(component1Result.ParameterValues, options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, Math.Abs(ctx.Expectation * 0.001)))
                .WhenTypeIs<double>());
            sumResult.ParameterValues.TakeLast(4).Should().BeEquivalentTo(component2Result.ParameterValues, options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, Math.Abs(ctx.Expectation * 0.001)))
                .WhenTypeIs<double>());
            sumResult.ParameterCovarianceMatrix.SubMatrix(0,3,0,3).Should().BeEquivalentTo(component1Result.ParameterCovarianceMatrix, options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, Math.Abs(ctx.Expectation * 0.001)))
                .WhenTypeIs<double>());
            sumResult.ParameterCovarianceMatrix.SubMatrix(4,7,4,7).Should().BeEquivalentTo(component2Result.ParameterCovarianceMatrix, options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, Math.Abs(ctx.Expectation * 0.001)))
                .WhenTypeIs<double>());
            sumResult.ParameterCovarianceMatrix.SubMatrix(4,7,0,3).Should().BeEquivalentTo(AllZeroMatrix(4,4), options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, 1e-8))
                .WhenTypeIs<double>());
            sumResult.ParameterCovarianceMatrix.SubMatrix(0,3,4,7).Should().BeEquivalentTo(AllZeroMatrix(4,4), options => options
                .Using<double>(ctx => ctx.Subject.Should().BeApproximately(ctx.Expectation, 1e-8))
                .WhenTypeIs<double>());
        }
    }

    private static double[,] AllZeroMatrix(int rows, int columns) => new double[rows, columns];
}

file static class MatrixExtensions
{
    public static double[,] SubMatrix(this double[,] matrix, int firstRow, int lastRow, int firstColumn, int lastColumn)
    {
        var rows = lastRow - firstRow + 1;
        var cols = lastColumn - firstColumn + 1;
        var subMatrix = new double[rows, cols];
        
        for (var i = 0; i < rows; i++)
        for (var j = 0; j < cols; j++)
            subMatrix[i, j] = matrix[firstRow + i, firstColumn + j];

        return subMatrix;
    }
}

file static class CostFunctionExtensions
{
    public static ICostFunction WithUp(this ICostFunction costFunction, double up) => 
        new WrappedCostWithCustomUp(costFunction, up);
}

file class WrappedCostWithCustomUp(ICostFunction wrapped, double up) : ICostFunction
{
    public IList<string> Parameters => wrapped.Parameters;
    public bool HasGradient => wrapped.HasGradient;
    public double Up { get; } = up;
    public double ValueFor(IList<double> parameterValues) => wrapped.ValueFor(parameterValues);
    public IList<double> GradientFor(IList<double> parameterValues) => wrapped.GradientFor(parameterValues);
    public MinimizationResult Adjusted(MinimizationResult minimizationResult) => wrapped.Adjusted(minimizationResult);
}
